CSDI v1.2 Snapshot - Best Configuration
========================================
Created: Thu Jan  1 16:04:07 EST 2026
Git commit: N/A

Model Architecture:
- Type: Conditional Score-based Diffusion with Transformer backbone
- d_model: 256 (embedding dimension)
- n_heads: 8 (attention heads)
- n_layers: 6 (transformer layers)
- d_ff: 1024 (feedforward dimension)
- dropout: 0.1
- max_length: 512 (max trajectory length in seconds)
- Conditioning: avg_speed, duration, max_speed (3 features)

Diffusion Parameters:
- diffusion_steps: 200
- beta_start: 0.0001
- beta_end: 0.02
- schedule: cosine

Training Settings:
- epochs: 200
- batch_size: 32
- learning_rate: 1e-4
- smoothness_weight: 0.1 (temporal smoothness loss)
- speed_limit: 40.0 m/s (normalization ceiling)

Generation Settings (OPTIMAL):
- Smoothing kernel: 7 (sweet spot - balances smoothness vs distribution matching)
- Boundary ramp: 3 seconds (conditional - only applies if not already near zero)
- Condition sampling: from real data distribution

Results Summary:
- Speed Wasserstein: 0.736 (excellent)
- Accel Wasserstein: 0.080 (good)
- Discriminative Score: 0.499 (near-perfect, ~0.5 = indistinguishable)
- Boundary Violations: 0%
- LDLJ (jerk smoothness): -1.69 (synthetic smoother than real -0.47)

Known Limitations:
- Acceleration distribution has slightly lighter tails than real data
- LDLJ indicates synthetic trajectories are smoother than real

Future Improvements to Try:
1. Correlated noise post-processing (add medium-freq variation)
2. Retraining with acceleration distribution matching loss

Files Included:
- model/csdi_best.pt - Best trained model checkpoint
- results/*.csv - Generated trajectories
- results/*.png - Evaluation plots and samples
- results/*.json - Metrics
- logs/*.out, *.err - Training/generation logs
- code/ - Source code snapshot

To Reproduce:
1. Copy model file: cp v1.2/model/csdi_best.pt .
2. Generate: python csdi_trajectory.py --generate --model_path csdi_best.pt --smooth_kernel 7 --data_path ../../data/Microtrips
